{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ref: https://medium.com/@wilamelima/a-hands-on-intro-to-deep-learning-690d1354bfc4\n",
    "#ref: https://becominghuman.ai/a-hands-on-intro-to-anns-and-deep-learning-part-2-d776d6a93d21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from numpy import where\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>has_cabin_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "1     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "2     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
       "3     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
       "4     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "5     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "1  29.0000    0.0    0.0   24160  211.3375       B5        S    2    NaN   \n",
       "2   0.9167    1.0    2.0  113781  151.5500  C22 C26        S   11    NaN   \n",
       "3   2.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "4  30.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "5  25.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  has_cabin_number  \n",
       "1                     St Louis, MO                 1  \n",
       "2  Montreal, PQ / Chesterville, ON                 1  \n",
       "3  Montreal, PQ / Chesterville, ON                 1  \n",
       "4  Montreal, PQ / Chesterville, ON                 1  \n",
       "5  Montreal, PQ / Chesterville, ON                 1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass                 1\n",
      "survived               1\n",
      "name                   1\n",
      "sex                    1\n",
      "age                    0\n",
      "sibsp                  1\n",
      "parch                  1\n",
      "ticket                 1\n",
      "fare                   2\n",
      "cabin               1015\n",
      "embarked               0\n",
      "boat                 824\n",
      "body                1189\n",
      "home.dest            565\n",
      "has_cabin_number       0\n",
      "isAlone                0\n",
      "Age Category           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Handle with missing dat # Handle \n",
    "\n",
    "def isKid(data):\n",
    "\n",
    "    #Check if it's alone\n",
    "    isAlone = []\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        if row['sibsp'] == 0 and row['parch'] == 0:\n",
    "            isAlone.append(1)\n",
    "        else:\n",
    "            isAlone.append(0)\n",
    "        \n",
    "    data['isAlone'] = isAlone\n",
    "\n",
    "    # Check if it's adult, kid or senior\n",
    "    age_cat = [] \n",
    "    \n",
    "    for i, row in data.iterrows():        \n",
    "        if np.isnan(row['age']) == True and row['isalone'] == 1:\n",
    "            age_cat.append(2)    \n",
    "        elif np.isnan(row['age']) == True and row['isalone'] == 0:\n",
    "            if row['sibsp'] >= 0:\n",
    "                age_cat.append(2)\n",
    "        elif row['age'] <= 14:\n",
    "            age_cat.append(1)\n",
    "        elif row['age'] >= 60:\n",
    "            age_cat.append(3)\n",
    "        elif row['age'] >= 15 and row['age'] <= 59:\n",
    "            age_cat.append(2)\n",
    "        else:\n",
    "            age_cat.append(None)\n",
    "            \n",
    "    data['Age Category'] = age_cat\n",
    "\n",
    "    # Fill age column with the median for each category\n",
    "    kids_median = data['age'].where(data['Age Category'] == 1).median()\n",
    "    adults_median = data['age'].where(data['Age Category'] == 2).median()\n",
    "    seniors_median = data['age'].where(data['Age Category'] == 3).median()\n",
    "    global_median = data['age'].median()\n",
    "    ages = []\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        if np.isnan(row['age']) != True:\n",
    "            ages.append(row['age'])\n",
    "        elif np.isnan(row['age']) == True and row['Age Category'] == 1:\n",
    "            ages.append(kids_median)\n",
    "        elif np.isnan(row['age']) == True and row['Age Category'] == 2:\n",
    "            ages.append(adults_median)\n",
    "        elif np.isnan(row['age']) == True and row['Age Category'] == 3:\n",
    "            ages.append(seniors_median)\n",
    "        else:\n",
    "            ages.append(global_median)\n",
    "    \n",
    "    data['age'] = ages\n",
    "    \n",
    "    # Deal with empty Age Category \n",
    "    age_cat = []\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        if np.isnan(row['Age Category']) == True:\n",
    "            age_cat.append(data['Age Category'].mode()[0])\n",
    "        else:\n",
    "            age_cat.append(row['Age Category'])\n",
    "            \n",
    "    data['Age Category'] = age_cat\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = isKid(data)\n",
    "\n",
    "mode  =  data.embarked.mode()\n",
    "data.embarked = data.embarked.fillna(value=mode[0])\n",
    "\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical data\n",
    "\n",
    "def dummify_dataset(data):\n",
    "    data = pd.concat([data, pd.get_dummies(data.sex, prefix='Sex')],axis=1)\n",
    "    data = pd.concat([data, pd.get_dummies(data.embarked, prefix='Embarked')],axis=1)\n",
    "    data = pd.concat([data, pd.get_dummies(data.pclass, prefix='Pclass')],axis=1)\n",
    "    data = pd.concat([data, pd.get_dummies(data.isAlone, prefix='isAlone')],axis=1)\n",
    "    data = pd.concat([data, pd.get_dummies(data['Age Category'], prefix='AgeCat')],axis=1)\n",
    "    \n",
    "    \n",
    "    data = data.drop(['name', 'boat','ticket' ,'body','cabin','home.dest' ,'sex','embarked', 'pclass', 'isAlone', 'Age Category', 'Sex_female', 'Embarked_C', 'Pclass_1.0', 'isAlone_0', 'AgeCat_1.0'], axis=1)\n",
    "    \n",
    "    data = data.rename(index=str, columns = {'Sex_male':'Sex'})\n",
    "    \n",
    "    print(data.columns)\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'age', 'sibsp', 'parch', 'fare', 'has_cabin_number', 'Sex',\n",
      "       'Embarked_Q', 'Embarked_S', 'Pclass_2.0', 'Pclass_3.0', 'isAlone_1',\n",
      "       'AgeCat_2.0', 'AgeCat_3.0'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>has_cabin_number</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>isAlone_1</th>\n",
       "      <th>AgeCat_2.0</th>\n",
       "      <th>AgeCat_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived   age  sibsp  parch      fare  has_cabin_number  Sex  Embarked_Q  \\\n",
       "1       1.0  29.0    0.0    0.0  211.3375                 1    0           0   \n",
       "\n",
       "   Embarked_S  Pclass_2.0  Pclass_3.0  isAlone_1  AgeCat_2.0  AgeCat_3.0  \n",
       "1           1           0           0          1           1           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dummify_dataset(data)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived            1\n",
       "age                 0\n",
       "sibsp               1\n",
       "parch               1\n",
       "fare                2\n",
       "has_cabin_number    0\n",
       "Sex                 0\n",
       "Embarked_Q          0\n",
       "Embarked_S          0\n",
       "Pclass_2.0          0\n",
       "Pclass_3.0          0\n",
       "isAlone_1           0\n",
       "AgeCat_2.0          0\n",
       "AgeCat_3.0          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>has_cabin_number</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>isAlone_1</th>\n",
       "      <th>AgeCat_2.0</th>\n",
       "      <th>AgeCat_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived      age  sibsp  parch      fare  has_cabin_number  Sex  \\\n",
       "1       1.0  29.0000    0.0    0.0  211.3375                 1    0   \n",
       "2       1.0   0.9167    1.0    2.0  151.5500                 1    1   \n",
       "3       0.0   2.0000    1.0    2.0  151.5500                 1    0   \n",
       "4       0.0  30.0000    1.0    2.0  151.5500                 1    1   \n",
       "5       0.0  25.0000    1.0    2.0  151.5500                 1    0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Pclass_2.0  Pclass_3.0  isAlone_1  AgeCat_2.0  \\\n",
       "1           0           1           0           0          1           1   \n",
       "2           0           1           0           0          0           0   \n",
       "3           0           1           0           0          0           0   \n",
       "4           0           1           0           0          0           1   \n",
       "5           0           1           0           0          0           1   \n",
       "\n",
       "   AgeCat_3.0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>has_cabin_number</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>isAlone_1</th>\n",
       "      <th>AgeCat_2.0</th>\n",
       "      <th>AgeCat_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      survived        age  sibsp  parch  fare  has_cabin_number  Sex  \\\n",
       "1310       NaN  29.881135    NaN    NaN   NaN                 0    0   \n",
       "\n",
       "      Embarked_Q  Embarked_S  Pclass_2.0  Pclass_3.0  isAlone_1  AgeCat_2.0  \\\n",
       "1310           0           1           0           0          0           1   \n",
       "\n",
       "      AgeCat_3.0  \n",
       "1310           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[np.isnan(data['survived'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[np.isnan(data['survived'])].index, axis = 0, inplace=True)\n",
    "data.drop(data[np.isnan(data['fare'])].index, axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scale the data\n",
    "\n",
    "y = data.survived\n",
    "X = data.drop('survived', axis = 1)\n",
    "\n",
    "# Divide into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state=0)\n",
    "\n",
    "# Apply the Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "classifier.add(Dense(units=7, \n",
    "                     kernel_initializer = 'he_normal', \n",
    "                     activation = 'relu', \n",
    "                     input_dim = 13))\n",
    "\n",
    "# Hidden layer\n",
    "classifier.add(Dense(units=7,\n",
    "                     kernel_initializer='he_normal',\n",
    "                     activation='relu'))\n",
    "\n",
    "# Output\n",
    "classifier.add(Dense(units=1,\n",
    "                     kernel_initializer='he_normal',\n",
    "                     activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "\n",
    "classifier.compile(optimizer = 'adam', \n",
    "                   loss = 'binary_crossentropy', \n",
    "                   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train,\n",
    "               batch_size = 10,\n",
    "               epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b578cd861715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Transform into binary for the confucion matrix (0 or 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Transform into binary for the confucion matrix (0 or 1)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Analysis\n",
    "print('Accuracy score:', accuracy_score(y_test, y_pred))\n",
    "print(\"-\"*80)\n",
    "print('Confusion matrix\\n')\n",
    "conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "confusion = pd.DataFrame(conmat, index=['Actual survived', 'Actual died'],\n",
    "                         columns=['Predicted survived','Predicted died'])\n",
    "print(confusion)\n",
    "print(\"-\"*80)\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred, target_names=['1','0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about it: we didn’t have to do any feature selection and we almost didn’t tweak our model. We didn’t do any cross validation, we didn’t play with the number of hidden layers…\n",
    "\n",
    "So, there’s a lot of room for improvement here. We can do much more to obtain better results, but doing almost nothing was already enough to make us almost beat the old model. So, do you understand the potential of ANNs?\n",
    "\n",
    "On the part 2, write how we can improve the ANN performance. Check it here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 7, kernel_initializer = 'he_normal', activation = 'relu', input_dim = 13))\n",
    "    classifier.add(Dense(units = 7, kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'he_normal', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\n",
    "\n",
    "accuracies = cross_val_score(estimator = classifier, \n",
    "                             X = X_train, \n",
    "                             y = y_train, \n",
    "                             cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training, we check the average accuracy of the model and the average variance. We are trying to create a model with high accuracy and low variance, all of this avoiding overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(accuracies.mean())\n",
    "print(accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analysis\n",
    "print('Accuracy score:', accuracy_score(y_test, y_pred))\n",
    "print(\"-\"*80)\n",
    "print('Confusion matrix\\n')\n",
    "conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "confusion = pd.DataFrame(conmat, index=['Actual survived', 'Actual died'],\n",
    "                         columns=['Predicted survived','Predicted died'])\n",
    "print(confusion)\n",
    "print(\"-\"*80)\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred, target_names=['1','0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a few things: the average accuracy of the model is 81%, while the variance is relatively low (3%). After fitting the model, we can do some predictions. We have a surprise now: after applying cross validation, we had a much better accuracy of 83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to reduce overfit risk is using dropout regularisation. It works by ‘disabling’ a few hidden and visible neurones during the training phase. In order to do it, we’ll rewrite our build_classifier() function adding the dropout instructions.\n",
    "\n",
    "We have to give an argument to the dropout function, which’s called rate. The rate is the probability of dropout for the neurones of a layer. We’ll use 10% as value here. But we’ll do more than just adding dropout. We also want to tweak our model a little bit.\n",
    "\n",
    "More neurones\n",
    "Let’s also add more neurones to our network. For the input layer, let’s use 1 neurone for each feature and an extra for a bias term (13 neurones in total). For the hidden layer, let’s use the average rule: the number of neurones is the average of the input layer and the output layer (7 neurones).\n",
    "\n",
    "Hyperparameters configuration\n",
    "We want to test different parameters to check which one work the most for our model. We do it by usingGridSearchCV. This method looks for the best combination of hyperparameters given a dictionary of values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rom keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Build classifier\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "\n",
    "    classifier.add(Dense(units = 13, kernel_initializer = 'he_normal', activation = 'relu', input_dim = 12))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(units = 7, kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'he_normal', activation = 'sigmoid'))\n",
    "    \n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "\n",
    "# Define params to test\n",
    "parameters = {'batch_size': [5, 20, 32],\n",
    "              'epochs': [50, 200, 500, 1000],\n",
    "              'optimizer': ['adam', 'rmsprop', 'adamax']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "\n",
    "# Give the data to test\n",
    "grid_search = grid_search.fit(X_train, \n",
    "                              y_train,\n",
    "                              class_weight={1:10,0:5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the best parameters and score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print('\\nAccuracy score:', accuracy_score(y_test, y_pred))\n",
    "print(\"-\"*80)\n",
    "print('Confusion matrix\\n')\n",
    "conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "confusion = pd.DataFrame(conmat, index=['Actual survived', 'Actual died'],\n",
    "                         columns=['Predicted survived','Predicted died'])\n",
    "print(confusion)\n",
    "print(\"-\"*80)\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred, target_names=['1','0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we had an accuracy of 84% this time.\n",
    "\n",
    "There are plenty of possibilities here, as you may guess: changing the number of neurones, tuning the algorithm, adding layers, preprocessing even more the input data… There are actually no limits if you want to have even better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@wilamelima/why-you-should-not-trust-only-in-accuracy-to-measure-machine-learning-performance-a72cf00b4516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
