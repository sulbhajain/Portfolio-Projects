{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ref: https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(dataset_url, sep=';')\n",
    " \n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data.quality\n",
    "X = data.drop('quality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.51358886  2.19680282 -0.164433   ...  1.08415147 -0.69866131\n",
      "  -0.58608178]\n",
      " [-1.73698885 -0.31792985 -0.82867679 ...  1.46964764  1.2491516\n",
      "   2.97009781]\n",
      " [-0.35201795  0.46443143 -0.47100705 ... -0.13658641 -0.35492962\n",
      "  -0.20843439]\n",
      " ...\n",
      " [-0.98679628  1.10708533 -0.93086814 ...  0.24890976 -0.98510439\n",
      "   0.35803669]\n",
      " [-0.69826067  0.46443143 -1.28853787 ...  1.08415147 -0.35492962\n",
      "  -0.68049363]\n",
      " [ 3.1104093  -0.62528606  2.08377675 ... -1.61432173  0.79084268\n",
      "  -0.39725809]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization is the process of subtracting the means from each feature and then dividing \n",
    "# by the feature standard deviations.\n",
    "# algorithms assume that all features are centered around zero and have approximately the same variance.\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "print (X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.16664562e-16 -3.05550043e-17 -8.47206937e-17 -2.22218213e-17\n",
      "  2.22218213e-17 -6.38877362e-17 -4.16659149e-18 -2.54439854e-15\n",
      " -8.70817622e-16 -4.08325966e-16 -1.17220107e-15]\n"
     ]
    }
   ],
   "source": [
    "# scaled dataset is indeed centered at zero, with unit variance:\n",
    "print (X_train_scaled.mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (X_train_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as similar transformation cannot be applied on the test data due to diff of mean and STD dev.\n",
    "# so need to use transformer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the transformer on training set\n",
    "# apply the transformation on training set\n",
    "# apply the transformation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaler has been trained on mean/STD of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.16664562e-16 -3.05550043e-17 -8.47206937e-17 -2.22218213e-17\n",
      "  2.22218213e-17 -6.38877362e-17 -4.16659149e-18 -2.54439854e-15\n",
      " -8.70817622e-16 -4.08325966e-16 -1.17220107e-15]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# confirm the sacled data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    " \n",
    "print (X_train_scaled.mean(axis=0))\n",
    "\n",
    "print (X_train_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02776704  0.02592492 -0.03078587 -0.03137977 -0.00471876 -0.04413827\n",
      " -0.02414174 -0.00293273 -0.00467444 -0.10894663  0.01043391]\n",
      "[1.02160495 1.00135689 0.97456598 0.91099054 0.86716698 0.94193125\n",
      " 1.03673213 1.03145119 0.95734849 0.83829505 1.0286218 ]\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    " \n",
    "print (X_test_scaled.mean(axis=0))\n",
    "\n",
    "print (X_test_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# even here too the mean is not centered around zero but has unit std deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# buid modeling pipeline having standarization for transformation and model to fit\n",
    "# Declare data preprocessing steps\n",
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                             RandomForestRegressor(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters express \"higher-level\" structural information about the model, and they are typically set before \n",
    "# training the model.\n",
    "# So tuning is required for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False))], 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True), 'randomforestregressor': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False), 'standardscaler__copy': True, 'standardscaler__with_mean': True, 'standardscaler__with_std': True, 'randomforestregressor__bootstrap': True, 'randomforestregressor__criterion': 'mse', 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__max_leaf_nodes': None, 'randomforestregressor__min_impurity_decrease': 0.0, 'randomforestregressor__min_impurity_split': None, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__min_weight_fraction_leaf': 0.0, 'randomforestregressor__n_estimators': 100, 'randomforestregressor__n_jobs': 1, 'randomforestregressor__oob_score': False, 'randomforestregressor__random_state': None, 'randomforestregressor__verbose': 0, 'randomforestregressor__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print (pipeline.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare hyperparameters to tune\n",
    "hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a process for reliably estimating the performance of a method for building a model by training and evaluating your model multiple times using the same method.\n",
    "\n",
    "Practically, that \"method\" is simply a set of hyperparameters in this context.\n",
    "\n",
    "These are the steps for CV:\n",
    "\n",
    "Split your data into k equal parts, or \"folds\" (typically k=10).\n",
    "Train your model on k-1 folds (e.g. the first 9 folds).\n",
    "Evaluate it on the remaining \"hold-out\" fold (e.g. the 10th fold).\n",
    "Perform steps (2) and (3) k times, each time holding out a different fold.\n",
    "Aggregate the performance across all k folds. This is your performance metric.\n",
    "The best practice when performing CV is to include your data preprocessing steps inside the cross-validation loop. This prevents accidentally tainting your training folds with influential data from your test fold.\n",
    "\n",
    "Here's how the CV pipeline looks after including preprocessing steps:\n",
    "\n",
    "Split your data into k equal parts, or \"folds\" (typically k=10).\n",
    "Preprocess k-1 training folds.\n",
    "Train your model on the same k-1 folds.\n",
    "Preprocess the hold-out fold using the same transformations from step (2).\n",
    "Evaluate your model on the same hold-out fold.\n",
    "Perform steps (2) - (5) k times, each time holding out a different fold.\n",
    "Aggregate the performance across all k folds. This is your performance metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decr...mators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'randomforestregressor__max_features': ['auto', 'sqrt', 'log2'], 'randomforestregressor__max_depth': [None, 5, 3, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune model using cross-validation pipeline\n",
    "# CV is needed to tune hyperparameters like maximum depth\n",
    "\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=10)\n",
    " \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestregressor__max_depth': None,\n",
       " 'randomforestregressor__max_features': 'sqrt'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the best set of parameters\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuned your hyperparameters appropriately using cross-validation, you can generally get a small performance improvement by refitting the model on the entire training set.\n",
    "\n",
    "Conveniently, GridSearchCV from sklearn will automatically refit the model with the best set of hyperparameters using the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print (clf.refit)\n",
    "# so no refttting is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  0.47022119983049837\n",
      "MSE:  0.34185218749999996\n",
      "RMSE:  5.8468127000956684\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model pipeline on test data\n",
    "pred = clf.predict(X_test)\n",
    "print (\"R2 score: \", r2_score(y_test, pred))\n",
    "print (\"MSE: \",mean_squared_error(y_test, pred))\n",
    " \n",
    "print (\"RMSE: \", np.sqrt( mean_squared_error(y_test, pred)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as erros are low so model performed well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_regressor.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model for future use. joblob is more efficient as compared to pickle as it can store large numpy arrays\n",
    "joblib.dump(clf, 'rf_regressor.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.53, 5.74, 4.98, 5.6 , 6.31, 5.67, 4.95, 4.86, 5.02, 6.06, 5.22,\n",
       "       5.68, 5.81, 5.14, 5.82, 5.63, 6.71, 5.65, 5.74, 6.97, 5.46, 5.76,\n",
       "       5.04, 5.97, 5.94, 5.04, 5.47, 5.19, 5.9 , 5.9 , 5.91, 6.56, 6.  ,\n",
       "       4.99, 5.01, 5.89, 5.05, 6.1 , 4.97, 6.06, 4.92, 5.99, 6.66, 5.14,\n",
       "       6.21, 5.3 , 5.59, 5.61, 5.15, 6.42, 5.97, 5.23, 5.84, 5.1 , 5.61,\n",
       "       5.62, 5.37, 5.34, 4.99, 5.18, 5.28, 5.15, 5.1 , 5.85, 5.99, 5.25,\n",
       "       6.38, 5.08, 5.19, 6.56, 5.72, 5.76, 5.11, 5.04, 5.29, 5.95, 5.29,\n",
       "       5.14, 5.38, 5.3 , 6.37, 5.73, 6.12, 6.41, 5.11, 6.03, 6.45, 6.1 ,\n",
       "       5.86, 5.92, 6.01, 5.4 , 6.52, 5.61, 5.73, 5.71, 6.81, 6.72, 5.61,\n",
       "       6.75, 5.12, 5.44, 5.1 , 6.38, 5.04, 4.83, 5.63, 5.03, 5.79, 5.96,\n",
       "       5.87, 5.49, 6.07, 5.41, 5.21, 5.19, 5.94, 5.06, 4.93, 5.93, 5.94,\n",
       "       5.03, 5.73, 6.15, 5.3 , 5.33, 5.32, 6.09, 5.45, 5.46, 5.92, 6.17,\n",
       "       5.18, 5.39, 5.14, 6.46, 5.02, 5.18, 6.78, 5.5 , 5.25, 5.05, 5.78,\n",
       "       6.06, 5.28, 5.38, 5.08, 6.56, 5.88, 5.07, 5.59, 5.18, 4.96, 5.03,\n",
       "       5.29, 5.88, 5.35, 5.8 , 5.85, 5.29, 5.62, 5.22, 5.17, 5.93, 5.  ,\n",
       "       5.99, 5.15, 5.3 , 5.52, 5.1 , 6.02, 5.19, 5.54, 5.06, 5.59, 5.47,\n",
       "       4.97, 5.39, 5.52, 5.04, 6.01, 5.58, 5.04, 5.  , 5.15, 6.2 , 5.18,\n",
       "       5.59, 5.26, 4.83, 5.48, 6.56, 5.8 , 5.9 , 5.49, 5.19, 5.43, 5.12,\n",
       "       6.26, 4.86, 6.36, 5.02, 5.26, 5.24, 6.86, 6.07, 5.3 , 5.24, 5.36,\n",
       "       5.88, 5.77, 5.99, 5.9 , 6.28, 5.78, 5.97, 5.19, 5.23, 5.71, 5.28,\n",
       "       5.23, 6.06, 6.07, 5.48, 5.9 , 5.89, 5.56, 6.26, 5.44, 5.73, 5.48,\n",
       "       5.48, 6.22, 5.65, 4.85, 4.47, 6.63, 6.53, 6.31, 5.34, 5.39, 5.44,\n",
       "       5.45, 6.29, 5.9 , 5.21, 5.11, 5.47, 5.36, 6.41, 5.18, 5.06, 5.12,\n",
       "       5.05, 5.91, 6.32, 5.77, 5.35, 5.47, 6.4 , 5.55, 5.94, 5.28, 5.21,\n",
       "       5.79, 5.9 , 5.88, 5.59, 5.41, 5.1 , 5.74, 5.53, 6.52, 6.04, 5.55,\n",
       "       4.93, 5.92, 6.5 , 6.03, 5.35, 5.47, 5.39, 5.29, 6.08, 6.85, 5.34,\n",
       "       6.55, 5.8 , 5.42, 5.32, 5.71, 5.19, 5.22, 6.23, 5.8 , 6.  , 6.05,\n",
       "       5.99, 5.38, 5.78, 5.57, 6.18, 5.63, 6.84, 6.81, 5.9 , 6.22, 5.09,\n",
       "       5.37, 5.89, 5.25, 5.34, 6.06, 6.48, 6.43, 5.16, 5.51, 5.7 , 6.13,\n",
       "       5.47])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To load sometime later\n",
    "clf2 = joblib.load('rf_regressor.pkl')\n",
    "\n",
    "# Predict data set using loaded model\n",
    "clf2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
